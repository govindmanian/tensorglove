{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize(embed):\n",
    "    m, n = embed.shape\n",
    "    for i in xrange(m):\n",
    "        embed[i] = embed[i] / np.linalg.norm(embed[i])\n",
    "    return embed\n",
    "\n",
    "dim = 100\n",
    "with open(\"vectors.txt\", 'r') as glove:\n",
    "    words = []\n",
    "    lines = glove.readlines()\n",
    "    embed = np.zeros((len(lines) - 1, dim))\n",
    "    body = lines[:-1]\n",
    "    i = 0\n",
    "    for vec in body:\n",
    "        tokens = vec.split()\n",
    "        words.append(tokens[0])\n",
    "        embed[i] = np.asarray([float(x) for x in tokens[1:]])\n",
    "        i = i + 1\n",
    "eembed = embed\n",
    "embed = normalize(embed)\n",
    "with open(\"cellvectors.txt\", 'r') as cov:\n",
    "    lines = cov.readlines()\n",
    "    cembed = np.zeros((len(lines) - 1, dim))\n",
    "    body = lines[:-1]\n",
    "    i = 0\n",
    "    for vec in body:\n",
    "        tokens = vec.split()\n",
    "        cembed[i] = np.asarray([abs(float(x)) for x in tokens[1:]])\n",
    "        i = i + 1\n",
    "ccembed = cembed\n",
    "ncembed = normalize(cembed)\n",
    "with open(\"timevectors.txt\", 'r') as cov2:\n",
    "    lines = cov2.readlines()\n",
    "    tembed = np.zeros((len(lines) - 1, dim))\n",
    "    body = lines[:-1]\n",
    "    i = 0\n",
    "    for vec in body:\n",
    "        tokens = vec.split()\n",
    "        tembed[i] = np.asarray([abs(float(x)) for x in tokens[1:]])\n",
    "        i = i + 1\n",
    "ttembed = tembed\n",
    "ntembed = normalize(tembed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative ('Conservative', 'PoliticalDiscussion', 'The_Donald', 'politics', 'NeutralPolitics', 'SandersForPresident') (0.0, 0.41259456137442091, 0.41442105586608696, 0.44952437824958497, 0.49336091928311798, 0.607771709787985)\n",
      "NeutralPolitics ('NeutralPolitics', 'Conservative', 'PoliticalDiscussion', 'politics', 'SandersForPresident', 'The_Donald') (0.0, 0.49336091928311798, 0.62910879071942882, 0.69965567374286775, 0.70724902461629291, 0.74000275169282581)\n",
      "PoliticalDiscussion ('PoliticalDiscussion', 'politics', 'Conservative', 'SandersForPresident', 'The_Donald', 'NeutralPolitics') (0.0, 0.25444494913748816, 0.41259456137442091, 0.52432396009503701, 0.55401890558466604, 0.62910879071942882)\n",
      "SandersForPresident ('SandersForPresident', 'politics', 'PoliticalDiscussion', 'Conservative', 'The_Donald', 'NeutralPolitics') (0.0, 0.47539614841455968, 0.52432396009503701, 0.607771709787985, 0.62562105949645497, 0.70724902461629291)\n",
      "The_Donald ('The_Donald', 'Conservative', 'politics', 'PoliticalDiscussion', 'SandersForPresident', 'NeutralPolitics') (0.0, 0.41442105586608696, 0.51479308695492876, 0.55401890558466604, 0.62562105949645497, 0.74000275169282581)\n",
      "politics ('politics', 'PoliticalDiscussion', 'Conservative', 'SandersForPresident', 'The_Donald', 'NeutralPolitics') (0.0, 0.25444494913748816, 0.44952437824958497, 0.47539614841455968, 0.51479308695492876, 0.69965567374286775)\n"
     ]
    }
   ],
   "source": [
    "subs = [\"Conservative\", \"NeutralPolitics\", \"PoliticalDiscussion\", \"SandersForPresident\", \"The_Donald\", \"politics\"]\n",
    "\n",
    "for i in xrange(len(ncembed)):\n",
    "    comp = subs\n",
    "    dists = []\n",
    "    for j in xrange(len(ncembed)):\n",
    "        dists.append(np.linalg.norm(ncembed[i] - ncembed[j]))\n",
    "    dists, comp = zip(*sorted(zip(dists, comp)))\n",
    "    print subs[i], comp, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (1, 2, 4, 3, 6, 5, 12, 8, 7, 10, 9, 11) (0.0, 0.21990273082481704, 0.28361566488878481, 0.29638912884176727, 0.37767671142094605, 0.38162857970619207, 0.42207871643284317, 0.44925505041548813, 0.45114187362535851, 0.48336088190505688, 0.49511186889653142, 0.51660021090649644)\n",
      "2 (2, 1, 4, 3, 5, 6, 12, 7, 10, 11, 8, 9) (0.0, 0.21990273082481704, 0.25044572268304938, 0.25657554738386301, 0.33210059029559025, 0.33399039019360777, 0.35557891572348765, 0.4112058950104972, 0.42448597660630782, 0.42480143548663429, 0.43588266110356894, 0.45668295435755857)\n",
      "3 (3, 4, 2, 5, 1, 6, 7, 12, 11, 8, 9, 10) (0.0, 0.1918660094868378, 0.25657554738386301, 0.2899315637044535, 0.29638912884176727, 0.34279683552188922, 0.3907810174150731, 0.40980468206222342, 0.4350545417006203, 0.4406991074402844, 0.46792793887568684, 0.49029643544469664)\n",
      "4 (4, 3, 5, 2, 6, 1, 7, 12, 8, 11, 9, 10) (0.0, 0.1918660094868378, 0.22142413601287481, 0.25044572268304938, 0.25681951814960541, 0.28361566488878481, 0.34338706868333324, 0.35993214748903096, 0.38278604339307765, 0.42092541732455974, 0.44104181759531047, 0.4478468614602289)\n",
      "5 (5, 6, 4, 3, 7, 2, 12, 8, 1, 11, 9, 10) (0.0, 0.22005817105327327, 0.22142413601287481, 0.2899315637044535, 0.32982745382980366, 0.33210059029559025, 0.36201053785391452, 0.37151797688936372, 0.38162857970619207, 0.38381806385797262, 0.42763426248647951, 0.44331769410506122)\n",
      "6 (6, 5, 7, 4, 8, 2, 12, 3, 9, 10, 1, 11) (0.0, 0.22005817105327327, 0.24746697227675382, 0.25681951814960541, 0.28507139543278537, 0.33399039019360777, 0.34271076648180776, 0.34279683552188922, 0.34286089215689519, 0.36749570007800536, 0.37767671142094605, 0.40000257914234888)\n",
      "7 (7, 8, 9, 6, 5, 4, 10, 11, 12, 3, 2, 1) (0.0, 0.21272566460476294, 0.24490493597965604, 0.24746697227675382, 0.32982745382980366, 0.34338706868333324, 0.35637490093581886, 0.36781556838124907, 0.37944742556074051, 0.3907810174150731, 0.4112058950104972, 0.45114187362535851)\n",
      "8 (8, 7, 9, 6, 5, 4, 10, 12, 2, 3, 11, 1) (0.0, 0.21272566460476294, 0.22647655931368049, 0.28507139543278537, 0.37151797688936372, 0.38278604339307765, 0.39171804556944584, 0.42832125941402771, 0.43588266110356894, 0.4406991074402844, 0.44227464652385251, 0.44925505041548813)\n",
      "9 (9, 8, 7, 6, 10, 11, 5, 4, 12, 2, 3, 1) (0.0, 0.22647655931368049, 0.24490493597965604, 0.34286089215689519, 0.38797911894657061, 0.41070152765407281, 0.42763426248647951, 0.44104181759531047, 0.44275948066849619, 0.45668295435755857, 0.46792793887568684, 0.49511186889653142)\n",
      "10 (10, 11, 12, 7, 6, 9, 8, 2, 5, 4, 1, 3) (0.0, 0.31981702111958021, 0.32044174766784983, 0.35637490093581886, 0.36749570007800536, 0.38797911894657061, 0.39171804556944584, 0.42448597660630782, 0.44331769410506122, 0.4478468614602289, 0.48336088190505688, 0.49029643544469664)\n",
      "11 (11, 10, 12, 7, 5, 6, 9, 4, 2, 3, 8, 1) (0.0, 0.31981702111958021, 0.32821102336034153, 0.36781556838124907, 0.38381806385797262, 0.40000257914234888, 0.41070152765407281, 0.42092541732455974, 0.42480143548663429, 0.4350545417006203, 0.44227464652385251, 0.51660021090649644)\n",
      "12 (12, 10, 11, 6, 2, 4, 5, 7, 3, 1, 8, 9) (0.0, 0.32044174766784983, 0.32821102336034153, 0.34271076648180776, 0.35557891572348765, 0.35993214748903096, 0.36201053785391452, 0.37944742556074051, 0.40980468206222342, 0.42207871643284317, 0.42832125941402771, 0.44275948066849619)\n"
     ]
    }
   ],
   "source": [
    "times = range(1, 13)\n",
    "\n",
    "for i in xrange(len(ntembed)):\n",
    "    comp = times\n",
    "    dists = []\n",
    "    for j in xrange(len(ntembed)):\n",
    "        dists.append(np.linalg.norm(ntembed[i] - ntembed[j]))\n",
    "    dists, comp = zip(*sorted(zip(dists, comp)))\n",
    "    print times[i], comp, dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word drift\n",
    "\n",
    "Which words change the most from subreddit to subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_embed = {}\n",
    "for k in xrange(len(subs)):\n",
    "    m, n = embed.shape\n",
    "    sub_specific_embed = np.zeros((m, n))\n",
    "    for i in xrange(m):\n",
    "        sub_specific_embed[i] = np.multiply(embed[i], ccembed[k])\n",
    "    sub_embed[subs[k]] = normalize(sub_specific_embed)\n",
    "    \n",
    "time_embed = {}\n",
    "for k in xrange(len(times)):\n",
    "    m, n = embed.shape\n",
    "    time_specific_embed = np.zeros((m, n))\n",
    "    for i in xrange(m):\n",
    "        time_specific_embed[i] = np.multiply(embed[i], ttembed[k])\n",
    "    time_embed[times[k]] = normalize(time_specific_embed)\n",
    "    \n",
    "sub_time_embed = {}\n",
    "for sub in xrange(len(subs)):\n",
    "    for time in xrange(len(times)):\n",
    "        m, n = embed.shape\n",
    "        sub_time_specific_embed = np.zeros((m, n))\n",
    "        for i in xrange(m):\n",
    "            sub_time_specific_embed[i] = np.multiply(np.multiply(embed[i], ttembed[time]), ccembed[sub])\n",
    "        sub_time_embed[(subs[sub], times[time])] = normalize(sub_time_specific_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_drift(sub1, sub2, w):\n",
    "    wp = w\n",
    "    m, n = embed.shape\n",
    "    sub1_embed = sub_embed[sub1]\n",
    "    sub2_embed = sub_embed[sub2]\n",
    "    drifts = [np.linalg.norm(np.asarray([np.linalg.norm(sub1_embed[i] - sub1_embed[j]) for j in xrange(1000)]) - np.asarray([np.linalg.norm(sub2_embed[i] - sub2_embed[j]) for j in xrange(1000)])) for i in xrange(1000)]\n",
    "    drifts, wp = zip(*sorted(zip(drifts, wp)))\n",
    "    return drifts, wp\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = most_drift(\"politics\", \"The_Donald\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sub_task(embed, sub_embed, words, subs, check):\n",
    "    # find pairs of words which are pushed together in a particular sub\n",
    "    sub_squeeze = {}\n",
    "    for k in xrange(len(subs)):\n",
    "        print k\n",
    "        sembed = sub_embed[subs[k]]\n",
    "        sort_pairs, sort_ranges = [], []\n",
    "        for i in xrange(len(check)):\n",
    "            for j in xrange(i):\n",
    "                sort_pairs.append((words[check[i]], words[check[j]]))\n",
    "                shift = np.linalg.norm(sembed[check[i]] - sembed[check[j]]) - np.linalg.norm(embed[check[i]] - embed[check[j]])\n",
    "                sort_ranges.append(shift)\n",
    "        sort_ranges, sort_pairs = zip(*sorted(zip(sort_ranges, sort_pairs)))\n",
    "        sub_squeeze[subs[k]] = (sort_ranges, sort_pairs)\n",
    "    return sub_squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "a = sub_task(embed, sub_embed, words, subs, common_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "common_words = pickle.load(open(\"common_words.p\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dict = {words[i] : i for i in xrange(len(words))}\n",
    "common_indices = [word_dict[word] for word in common_words[:2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump_push = a[\"The_Donald\"][1][::-1]\n",
    "sanders_push = a[\"SandersForPresident\"][1][::-1]\n",
    "politics_push = a[\"politics\"][1][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('biden', 'reagan'),\n",
       " ('comey', 'generally'),\n",
       " ('smaller', 'afford'),\n",
       " ('obamacare', 'buying'),\n",
       " ('buying', 'mass'),\n",
       " ('11', 'protest'),\n",
       " ('wealthy', 'mass'),\n",
       " ('arms', '90'),\n",
       " ('starts', 'meaning'),\n",
       " ('efforts', 'definitely'),\n",
       " ('aids', 'rpolitics'),\n",
       " ('independents', 'generally'),\n",
       " ('protest', 'door'),\n",
       " ('crisis', 'anybody'),\n",
       " ('african', 'bernies'),\n",
       " ('slightly', 'failed'),\n",
       " ('campaigns', 'stopped'),\n",
       " ('yep', 'sweden'),\n",
       " ('picked', 'signs'),\n",
       " ('warren', 'reagan'),\n",
       " ('b', 'afford'),\n",
       " ('transcripts', 'isis'),\n",
       " ('smaller', 'plus'),\n",
       " ('carson', 'rpolitics'),\n",
       " ('obamacare', 'heavily'),\n",
       " ('protest', 'wars'),\n",
       " ('biden', 'conservatives'),\n",
       " ('horrible', 'particularly'),\n",
       " ('nambla', 'ways'),\n",
       " ('beyond', 'mostly'),\n",
       " ('constantly', 'although'),\n",
       " ('search', 'keeping'),\n",
       " ('records', 'couldnt'),\n",
       " ('chicago', 'anywhere'),\n",
       " ('besides', 'image'),\n",
       " ('african', 'extreme'),\n",
       " ('arguing', 'successful'),\n",
       " ('available', 'wrote'),\n",
       " ('reports', 'mine'),\n",
       " ('notice', 'potential'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_push[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('officially', 'days'),\n",
       " ('americans', 'better'),\n",
       " ('911', 'michigan'),\n",
       " ('obamacare', 'science'),\n",
       " ('kek', 'obama'),\n",
       " ('911', 'ben'),\n",
       " ('latinos', 'protesters'),\n",
       " ('cruz', 'gop'),\n",
       " ('wealth', 'kinda'),\n",
       " ('growth', 'commit'),\n",
       " ('911', 'hitler'),\n",
       " ('statements', 'education'),\n",
       " ('sjw', 'today'),\n",
       " ('growth', 'expected'),\n",
       " ('buying', 'mass'),\n",
       " ('kek', 'if'),\n",
       " ('listening', 'americans'),\n",
       " ('marijuana', 'michigan'),\n",
       " ('officially', 'cool'),\n",
       " ('911', 'hours'),\n",
       " ('profit', 'changing'),\n",
       " ('blm', 'obama'),\n",
       " ('attack', 'kek'),\n",
       " ('colorado', 'rule'),\n",
       " ('911', 'schools'),\n",
       " ('particularly', 'pushing'),\n",
       " ('growth', 'demand'),\n",
       " ('colorado', 'accept'),\n",
       " ('illinois', 'marijuana'),\n",
       " ('deny', 'although'),\n",
       " ('islamic', 'today'),\n",
       " ('marijuana', 'e'),\n",
       " ('claiming', 'action'),\n",
       " ('911', '30'),\n",
       " ('buying', 'price'),\n",
       " ('besides', 'extreme'),\n",
       " ('buying', 'spread'),\n",
       " ('event', 'johnson'),\n",
       " ('constitutional', 'cruz'),\n",
       " ('banking', 'johnson'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanders_push[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12287, 20558, 33066, 37983, 18004, 14747, 32908, 32766, 14167, 32692]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12287"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('officially', 'days'),\n",
       " ('latinos', 'protesters'),\n",
       " ('someones', 'broken'),\n",
       " ('demand', 'ctr'),\n",
       " ('privilege', 'mom'),\n",
       " ('mom', 'c'),\n",
       " ('officially', 'needed'),\n",
       " ('mom', 'california'),\n",
       " ('cultural', 'protest'),\n",
       " ('someones', 'fix'),\n",
       " ('extension', '10'),\n",
       " ('officially', 'cool'),\n",
       " ('tweet', 'israel'),\n",
       " ('officially', '9'),\n",
       " ('profit', 'protesters'),\n",
       " ('wouldve', 'distance'),\n",
       " ('blm', 'kek'),\n",
       " ('protesters', 'claiming'),\n",
       " ('listening', 'h'),\n",
       " ('everywhere', 'medical'),\n",
       " ('buying', 'century'),\n",
       " ('pretend', 'reporting'),\n",
       " ('protesters', 'higher'),\n",
       " ('comey', 'besides'),\n",
       " ('blood', 'afford'),\n",
       " ('e', 'message'),\n",
       " ('talk', 'seen'),\n",
       " ('distance', 'positive'),\n",
       " ('videos', 'kinda'),\n",
       " ('movie', 'israel'),\n",
       " ('growth', 'demand'),\n",
       " ('body', 'feet'),\n",
       " ('0', 'google'),\n",
       " ('broke', 'feet'),\n",
       " ('itll', 'remaining'),\n",
       " ('distance', 'theyll'),\n",
       " ('san', 'protesters'),\n",
       " ('obamacare', 'science'),\n",
       " ('privilege', 'angry'),\n",
       " ('particularly', '\\xe2\\x80\\x8b'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics_push[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_words(word, sub, time, word_master):\n",
    "    w = word_master\n",
    "    index = word_dict[word]\n",
    "    emb = sub_time_embed[(sub, time)]\n",
    "    dists = [np.linalg.norm(emb[i] - emb[index]) for i in xrange(len(words))]\n",
    "    dists, w = zip(*sorted(zip(dists, w)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sanders',\n",
       " 'bernie',\n",
       " 'supporters',\n",
       " 'cruz',\n",
       " 'campaign',\n",
       " 'clinton',\n",
       " 'trump',\n",
       " 'fans',\n",
       " 'hillary',\n",
       " 'vs')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_words(\"sanders\", \"The_Donald\", 1, words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SandersForPresident', 8),\n",
       " ('The_Donald', 8),\n",
       " ('Conservative', 8),\n",
       " ('NeutralPolitics', 8),\n",
       " ('PoliticalDiscussion', 8),\n",
       " ('politics', 8)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_time_embed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_words(word, sub, time, word_master):\n",
    "    w = word_master\n",
    "    index = word_dict[word]\n",
    "    emb = sub_time_embed[(sub, time)]\n",
    "    emb_master = embed\n",
    "    dists = [np.linalg.norm(emb[i] - emb[index]) - np.linalg.norm(emb_master[i] - emb_master[index]) for i in xrange(len(words))]\n",
    "    dists, w = zip(*sorted(zip(dists, w)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arbusto',\n",
       " '65000ft',\n",
       " 'maga',\n",
       " 'te',\n",
       " 'nebraska',\n",
       " 'corroboration',\n",
       " 'lol',\n",
       " 'edit',\n",
       " 'neutralizing',\n",
       " 'descending',\n",
       " 'acquiesced',\n",
       " 'british',\n",
       " 'premeditation',\n",
       " '293645',\n",
       " 'while',\n",
       " 'syriza',\n",
       " 'anymore',\n",
       " 'themselves',\n",
       " 'winnertakemost',\n",
       " 'musing',\n",
       " 'ctr',\n",
       " 'meet',\n",
       " '514',\n",
       " 'tampermonkey',\n",
       " 'useraposs',\n",
       " 'greasemonkey',\n",
       " 'lost',\n",
       " 'relayed',\n",
       " 'break\\xe2\\x80\\x9d',\n",
       " 'bernie',\n",
       " 'virginia',\n",
       " 'hellscapes',\n",
       " 'indeed',\n",
       " 'borders',\n",
       " 'rpolitics',\n",
       " 'anyway',\n",
       " 'defend',\n",
       " 'overstaying',\n",
       " 'inflatable',\n",
       " 'moved')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_words(\"hillary\", \"The_Donald\", 2, words)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('howhowhowhow',\n",
       " 'nyquists',\n",
       " 'literally',\n",
       " 'seriously',\n",
       " 'totally',\n",
       " 'uusermane01',\n",
       " 'basically',\n",
       " 'squeaker',\n",
       " 'unplug',\n",
       " '031',\n",
       " 'hwoh',\n",
       " 'rossford',\n",
       " 'somehow',\n",
       " 'speaking',\n",
       " '210800',\n",
       " 'apparently',\n",
       " 'neurodivergent',\n",
       " '\\xe2\\x9e\\xb0',\n",
       " 'business',\n",
       " 'clearly',\n",
       " '50400',\n",
       " '9275',\n",
       " 'specific',\n",
       " 'obviously',\n",
       " '\\xe2\\x80\\x9clying\\xe2\\x80\\x9d',\n",
       " 'twitterfacebook',\n",
       " 'probably',\n",
       " 'fucking',\n",
       " 'stratum',\n",
       " 'stupid',\n",
       " 'having',\n",
       " 'evidencebased',\n",
       " 'clinton',\n",
       " 'wasnt',\n",
       " 'completely',\n",
       " 'wolfe',\n",
       " 'technology',\n",
       " 'team',\n",
       " 'idology',\n",
       " 'definitely')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_words(\"trump\", \"politics\", 7, words)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

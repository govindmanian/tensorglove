{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named praw",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4c22d81c75ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m reddit = praw.Reddit(client_id='9XzJ3alvrKUOYA', \n\u001b[1;32m      4\u001b[0m                      \u001b[0mclient_secret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VgHqKgYPECafjVpdasSAUUjxcG8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Working on project in changes in word embeddings in context of covariates. App to scrape data.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named praw"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id='9XzJ3alvrKUOYA', \n",
    "                     client_secret='VgHqKgYPECafjVpdasSAUUjxcG8', \n",
    "                     user_agent='Working on project in changes in word embeddings in context of covariates. App to scrape data.',\n",
    "                     username='',\n",
    "                     password=''\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def window(iterable, size, index):\n",
    "    return iterable[max(0, index - size) : index] + iterable[index + 1 : min(len(iterable), index + size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics\n",
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "31\n",
      "33\n",
      "35\n",
      "37\n",
      "39\n",
      "41\n",
      "43\n",
      "45\n",
      "47\n",
      "49\n",
      "51\n",
      "53\n",
      "55\n",
      "57\n",
      "59\n",
      "61\n",
      "63\n",
      "65\n",
      "67\n",
      "69\n",
      "71\n",
      "The_Donald\n",
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, string, pickle\n",
    "\n",
    "pilot = [\"Conservative\", \"NeutralPolitics\", \"PoliticalDiscussion\", \"SandersForPresident\", \"The_Donald\", \"politics\"]\n",
    "\n",
    "for i in xrange(len(pilot)):\n",
    "    sub = pilot[i]\n",
    "    print sub\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    for j in xrange(36):\n",
    "        print 2 * j + 1\n",
    "        cotensor = {}\n",
    "        get_subs = subreddit.submissions(1455062400 + (86400 * 5 * (2 * j + 1)), 1455062400 + (86400 * 5 * (2 * j + 1)) + 86400)\n",
    "        for submission in get_subs:\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            for comment in submission.comments.list():\n",
    "                if comment.score > 2:\n",
    "                    text = re.sub(r\"http\\S+\", '', ' '.join(comment.body.encode('utf-8').strip().lower().split()).translate(None, string.punctuation), flags=re.MULTILINE).split()\n",
    "                    if len(text) > 1:\n",
    "                        for word in xrange(len(text)):\n",
    "                            for context in window(text, 4, word):\n",
    "                                key = (text[word], context, sub)\n",
    "                                if key in cotensor:\n",
    "                                    cotensor[key] += 1\n",
    "                                else:\n",
    "                                    cotensor[key] = 1\n",
    "        pickle.dump(cotensor, open(sub + \"/\" + str(2 * j + 1) + \".p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cotensor = {}\n",
    "sublist = ['westworld_big_cotensor_999.p',\n",
    " 'westworld_big_cotensor_1362.p']\n",
    "for sub in sublist:\n",
    "    print sub\n",
    "    sub_cotensor = pickle.load(open(sub, 'rb'))\n",
    "    for key in sub_cotensor:\n",
    "        if key in cotensor:\n",
    "            cotensor[key] += sub_cotensor[key]\n",
    "        else:\n",
    "            cotensor[key] = sub_cotensor[key]\n",
    "len(cotensor.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "for key in cotensor:\n",
    "    a, b, c = key\n",
    "    if a in words:\n",
    "        words[a] += cotensor[key]\n",
    "    else:\n",
    "        words[a] = cotensor[key]\n",
    "    if b in words:\n",
    "        words[b] += cotensor[key]\n",
    "    else:\n",
    "        words[b] = cotensor[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = [words[w] for w in words]\n",
    "wordlist = words.keys()\n",
    "counts, wordlist = zip(*sorted(zip(counts, wordlist)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 21, 24]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(18, 27, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlist_fff, counts_fff = wordlist[176493:], counts[176493:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlist, count = wordlist_fff[::-1], counts_fff[::-1]\n",
    "word_dict = {wlist[i]: i for i in xrange(len(wlist))}\n",
    "pilot = ['nba', 'nfl', 'baseball', 'hockey', 'soccer', 'leagueoflegends', 'overwatch', 'GlobalOffensive', 'hearthstone', 'DotA2', 'gameofthrones', 'rickandmorty', 'thewalkingdead', 'breakingbad', 'westworld']\n",
    "cell_dict = {pilot[i]: i for i in xrange(len(pilot))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cotensor_f = {}\n",
    "for key in cotensor:\n",
    "    a, b, c = key\n",
    "    if a in word_dict and b in word_dict:\n",
    "        cotensor_f[(word_dict[a], word_dict[b], cell_dict[c])] = cotensor[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(cotensor_f, open(\"cotensor_f.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(word_dict, open(\"word_dict.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cotensor_f[(0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
